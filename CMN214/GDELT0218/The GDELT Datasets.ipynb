{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- [The GDELT Project](https://www.gdeltproject.org/)\n",
        "\n",
        "\n",
        "- Chen Luo, Feb 18, 2020"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What is GDELT?\n",
        "\n",
        "- GDELT = Global Database of Events, Language, and Tone\n",
        "\n",
        "- A project supported by Google, monitors the world's broadcast, print, and web news\n",
        "\n",
        "---\n",
        "\n",
        "## 2. What makes it special?\n",
        "\n",
        "- Multilanguage (Over 100)\n",
        "\n",
        "- A detailed coding system, including people, locations, organizations, themes, emotions\n",
        "\n",
        "- Open access\n",
        "\n",
        "- High update frequency (Every 15 mins)\n",
        "\n",
        "- Historical breadth (some datasets date back to the 19th century)\n",
        "\n",
        "- [Friendly documents](https://www.gdeltproject.org/data.html#documentation)\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Two major datasets\n",
        "\n",
        "- GDELT Event Database\n",
        "    - Contains over 300 categories of physical activities over the world\n",
        "    \n",
        "    - Nearly 280 themes\n",
        "    \n",
        "    - Nearly 60 attributes are coded for each event\n",
        "\n",
        "- GDELT Global Knowledge Graph (April 1, 2013 ~ now)\n",
        "    - Based on each news report, using NER and geocoding algorithms to perform the coding\n",
        "\n",
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. How to apply GDELT datasets to your network analysis?\n",
        "- Option 1: GDELT + Gephi\n",
        "    - [GKG Network Visualizer](http://analysis.gdeltproject.org/module-gkg-network.html)\n",
        "    \n",
        "    - Two steps: Enter your keywords, then open your mailbox\n",
        "    \n",
        "    - This function is not available now but will come into effect in the next few weeks.\n",
        "    \n",
        "    - There are other easy to use [analysis services](http://analysis.gdeltproject.org/)\n",
        "    \n",
        "    \n",
        "- Option 2: Customized data\n",
        "     - Google BigQuery / Raw data file (`csv` & `tsv`)\n",
        "     \n",
        "     - This following demo (very preliminary) creates a countries' co-occurrence (top 1K) network of `global pandemic` (a given theme in GDELT project) through news coverage in the recent week\n",
        "         - The toolkit includes Google BigQuery ([preview](https://bigquery.cloud.google.com/table/gdelt-bq), but please pay attention to the [quota](https://cloud.google.com/dialogflow/quotas)), Google Cloud Platform, Gephi (geolayout plug-in)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.cloud import bigquery\n",
        "from google.cloud.bigquery.job import QueryJobConfig\n",
        "\n",
        "# initialize\n",
        "QueryJobConfig(useLegacySql=False)\n",
        "# provide the private key of Google Cloud Platform\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = './gdelt-a776108ed74c.json'"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 query for the `edges.csv`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# `gdeltv2.gkg_partitioned` table stores the GKG V2 data (About 11 TB)\n",
        "# `extra.countrygeolookup` table contains countryname (str), lat (str), long (str), fips (str)\n",
        "# query_1 is for building the edges table (including source, target, type, weight)\n",
        "# 'OS' means oceans\n",
        "\n",
        "query_1 = '''\n",
        "SELECT\n",
        "  d.countryname Source, e.countryname Target, \"Undirected\" Type, ROUND(c.Count/SUM(c.Count) OVER (), 6) Weight\n",
        "FROM (\n",
        "  SELECT\n",
        "    a.countrycode Source, b.countrycode Target, COUNT(*) AS Count\n",
        "  FROM ( (\n",
        "      SELECT\n",
        "        DocumentIdentifier url, REGEXP_EXTRACT(location, r'^.*?#.*?#(.*?)#') countrycode\n",
        "      FROM\n",
        "        `gdelt-bq.gdeltv2.gkg_partitioned`, UNNEST(SPLIT(V2Locations, ';')) AS location\n",
        "      WHERE\n",
        "        LENGTH(V2Locations) > 3 AND V2Themes LIKE '%HEALTH_PANDEMIC%HEALTH_PANDEMIC%' AND DATE(_PARTITIONTIME) BETWEEN DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY) AND CURRENT_DATE())) a\n",
        "  JOIN ( (\n",
        "      SELECT\n",
        "        DocumentIdentifier url, REGEXP_EXTRACT(location, r'^.*?#.*?#(.*?)#') countrycode\n",
        "      FROM\n",
        "        `gdelt-bq.gdeltv2.gkg_partitioned`, UNNEST(SPLIT(V2Locations, ';')) AS location\n",
        "      WHERE\n",
        "        LENGTH(V2Locations) > 3 AND V2Themes LIKE '%HEALTH_PANDEMIC%HEALTH_PANDEMIC%' AND DATE(_PARTITIONTIME) BETWEEN DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY) AND CURRENT_DATE())) b\n",
        "  ON\n",
        "    a.url=b.url\n",
        "  WHERE\n",
        "    a.countrycode < b.countrycode AND a.countrycode != 'OS' AND b.countrycode != 'OS'\n",
        "  GROUP BY\n",
        "    1, 2\n",
        "  ORDER BY\n",
        "    3 DESC\n",
        "  LIMIT\n",
        "    1000) c\n",
        "JOIN (\n",
        "  SELECT\n",
        "    fips, countryname\n",
        "  FROM\n",
        "    `gdelt-bq.extra.countrygeolookup`) d\n",
        "ON\n",
        "  c.Source = d.fips\n",
        "JOIN (\n",
        "  SELECT\n",
        "    fips, countryname\n",
        "  FROM\n",
        "    `gdelt-bq.extra.countrygeolookup`) e\n",
        "ON\n",
        "  c.Target = e.fips\n",
        "ORDER BY\n",
        "  Count DESC\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 generate the `nodes.csv`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# query_2 is for building the nodes table (including ID, Label, Lat, Long)\n",
        "# Lat & Long fields are prepared for the geo-layout\n",
        "query_2 = '''\n",
        "SELECT\n",
        "  Country Id, Country Label, Latitude, Longitude\n",
        "FROM (\n",
        "  WITH\n",
        "    network AS(\n",
        "    SELECT\n",
        "      d.countryname Source, d.latitude SourceLatitude, d.longitude SourceLongitude, \n",
        "      e.countryname Target, e.latitude TargetLatitude, e.longitude TargetLongitude\n",
        "    FROM (\n",
        "      SELECT\n",
        "        a.countrycode Source, b.countrycode Target, COUNT(*) AS Count\n",
        "      FROM ( (\n",
        "          SELECT\n",
        "            DocumentIdentifier url, REGEXP_EXTRACT(location,r'^.*?#.*?#(.*?)#') countrycode\n",
        "          FROM\n",
        "            `gdelt-bq.gdeltv2.gkg_partitioned`, UNNEST(SPLIT(V2Locations, ';')) AS location\n",
        "          WHERE\n",
        "            LENGTH(V2Locations) > 3 AND V2Themes LIKE '%HEALTH_PANDEMIC%HEALTH_PANDEMIC%' AND DATE(_PARTITIONTIME) BETWEEN DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY) AND CURRENT_DATE())) a\n",
        "      JOIN ( (\n",
        "          SELECT\n",
        "            DocumentIdentifier url, REGEXP_EXTRACT(location,r'^.*?#.*?#(.*?)#') countrycode\n",
        "          FROM\n",
        "            `gdelt-bq.gdeltv2.gkg_partitioned`, UNNEST(SPLIT(V2Locations, ';')) AS location\n",
        "          WHERE\n",
        "            LENGTH(V2Locations) > 3 AND V2Themes LIKE '%HEALTH_PANDEMIC%HEALTH_PANDEMIC%' AND DATE(_PARTITIONTIME) BETWEEN DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY) AND CURRENT_DATE())) b\n",
        "      ON\n",
        "        a.url=b.url\n",
        "      WHERE\n",
        "        a.countrycode < b.countrycode AND a.countrycode != 'OS' AND b.countrycode != 'OS'\n",
        "      GROUP BY\n",
        "        1, 2\n",
        "      ORDER BY\n",
        "        3 DESC\n",
        "      LIMIT\n",
        "        1000) c\n",
        "    JOIN (\n",
        "      SELECT\n",
        "        fips, countryname, latitude, longitude\n",
        "      FROM\n",
        "        `gdelt-bq.extra.countrygeolookup`) d\n",
        "    ON\n",
        "      c.Source = d.fips\n",
        "    JOIN (\n",
        "      SELECT\n",
        "        fips, countryname, latitude, longitude\n",
        "      FROM\n",
        "        `gdelt-bq.extra.countrygeolookup`) e\n",
        "    ON\n",
        "      c.Target = e.fips\n",
        "    ORDER BY\n",
        "      Count DESC) (\n",
        "    SELECT\n",
        "      Source Country, SourceLatitude Latitude, SourceLongitude Longitude\n",
        "    FROM\n",
        "      network)\n",
        "  UNION DISTINCT (\n",
        "    SELECT\n",
        "      Target Country, TargetLatitude Latitude, TargetLongitude Longitude\n",
        "    FROM\n",
        "      network) )\n",
        "ORDER BY\n",
        "  Country\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 build the query module"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "class buildNetwork:\n",
        "    def __init__(self, query, filepath):\n",
        "        self.client = bigquery.Client()\n",
        "        self.query = query\n",
        "        self.filepath = filepath\n",
        "        self.idx = 0\n",
        "        \n",
        "    def query_process(self):\n",
        "        rows = self.client.query(self.query).result()\n",
        "        return rows\n",
        "    \n",
        "    def save_edges_results(self):\n",
        "        with open(self.filepath, 'w', encoding='utf-8') as edges:\n",
        "            edges.write('Source' + ',' + 'Target' + ',' + 'Type' + ',' + 'Weight' + '\\n')\n",
        "            for row in self.query_process():\n",
        "                self.idx += 1\n",
        "                edges.write(row['Source'] + ',' + row['Target'] + ',' + row['Type'] + ',' + str(row['Weight']) + '\\n')\n",
        "        return self.idx\n",
        "    \n",
        "    def save_nodes_results(self):\n",
        "        with open(self.filepath, 'w', encoding='utf-8') as nodes:\n",
        "            nodes.write('ID' + ',' + 'Label' + ',' + 'Latitude' + ',' + 'Longitude' + '\\n')\n",
        "            for row in self.query_process():\n",
        "                self.idx += 1\n",
        "                nodes.write(row['Id'] + ',' + row['Label'] + ',' + row['Latitude'] + ',' + str(row['Longitude']) + '\\n')\n",
        "        return self.idx"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4 run the query"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# for the edges\n",
        "newBuildNetwork = buildNetwork(query_1, './edges_pandemic.csv')\n",
        "newBuildNetwork.save_edges_results()\n",
        "print('This query generates %s edges'%(newBuildNetwork.idx))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This query generates 1001 edges\n",
            "CPU times: user 72.2 ms, sys: 10.5 ms, total: 82.8 ms\n",
            "Wall time: 7.11 s\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# for the nodes\n",
        "newBuildNetwork = buildNetwork(query_2, './nodes_pandemic.csv')\n",
        "newBuildNetwork.save_nodes_results()\n",
        "print('This query generates %s nodes'%(newBuildNetwork.idx))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This query generates 120 nodes\n",
            "CPU times: user 52.5 ms, sys: 7.23 ms, total: 59.7 ms\n",
            "Wall time: 7.96 s\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5 move to Gephi\n",
        "\n",
        "- The final network"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<img src='./final_network.png' width=1000 height=600>"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src='./final_network.png' width=1000 height=600>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Some studies using GDELT\n",
        "- [Vargo, C. J., Guo, L., & Amazeen, M. A. (2018). The agenda-setting power of fake news: A big data analysis of the online media landscape from 2014 to 2016. *New Media & Society*, *20*(5), 2028-2049.](https://journals.sagepub.com/doi/pdf/10.1177/1461444817712086)\n",
        "\n",
        "> This article uses **GDELT’s Global Knowledge Graph (GKG)** as its data source (Leetaru, 2012a, 2015a). On a daily basis, GDELT monitors news globally and employs a computer-assisted content analysis that identifies people, locations, themes, emotions, narratives, and events (Leetaru, 2015) The dataset has given researchers the ability to **computationally analyze news content of all sorts: real, fake, and fact-checking oriented** (Abbar et al., 2015; Vargo and Guo, 2017).\n",
        "\n",
        "- [Vargo, C. J., & Guo, L. (2017). Networks, big data, and intermedia agenda setting: An analysis of traditional, partisan, and emerging online U.S. news. *Journalism & Mass Communication Quarterly*, *94*(4), 1031-1055.](https://journals.sagepub.com/doi/pdf/10.1177/1077699016679976)\n",
        "\n",
        "> As the first big-data analysis that uses GDELT dataset to examine online intermedia agenda setting, our study focuses on the salience transfer of issues only. Given that **GDELT themes include both issues and attributes**, future research should consider analyzing NAS effects in terms of attributes, or a combination of issues and attributes. For example, **GDELT dataset identifies a number of different aspects of economy, for example, “Econ_Bankruptcy,” “Econ_Cost of living,” and “Econ_Debt.”** Researchers could investigate how news media associate different attributes of the economy issue, and then determine which medium leads and which follows.\n",
        "\n",
        "- [(Workshop paper) New media coverage of refugees in 2016: A GDELT case study](https://aaai.org/ocs/index.php/ICWSM/ICWSM17/paper/download/15778/14897)\n",
        "\n",
        "> We rely on the Global Database of Events, Language, and Tone (GDELT) project that monitors and analyses news articles around the world. In a ﬁrst phase, we explore the global media conversation on refugees along two important dimensions: **article quantity** and **sentiment**. We identify and characterize events that generated an extensive media coverage and also extreme sentiment in the news reports. In a second phase, we reﬁne the analysis by focusing on the news media coverage related to refugees in Europe. GDELT features allow us to identify the **key countries** and **time evolution** of the media coverage. Lastly, we determine the **main actors linked to refugees in the news and study their interaction through a network analysis**.\n",
        "\n",
        "- [(In Chinese) Pang, X. & Liu, Z. China-U.S. relations in massive machine-coded event data: Influence of reciprocity, policy inertia, and a third power. *World Economics and Politics*, *5*, 53-79.](https://github.com/LyndonChenLuo/Homework/tree/master/CMN214/GDELT0218/Pang&Liu.pdf)\n",
        "\n",
        "> Based the event data of directed actions between China and the United States between 1979 and 2017 from the Global Data on Events Location and Tone,this research is intended to investigate the effects of reciprocity,policy inertia,and third power( Russia) on how China and the U.S. cooperate or conflict with each other. We specify a **Vector Autoregressive Model** and rely on the **Impulse Response Functions** to identify the mutual effects of six time series of direct actions among China,the United States,and Russia."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "toc": {
      "toc_position": {},
      "skip_h1_title": false,
      "number_sections": false,
      "title_cell": "Table of Contents",
      "toc_window_display": true,
      "base_numbering": 1,
      "toc_section_display": true,
      "title_sidebar": "Contents",
      "toc_cell": false,
      "nav_menu": {},
      "sideBar": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}